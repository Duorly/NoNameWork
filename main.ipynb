{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-07T11:43:38.785516Z",
     "start_time": "2024-11-07T11:43:38.024376Z"
    }
   },
   "source": [
    "### Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, validation_curve\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T11:43:38.848036Z",
     "start_time": "2024-11-07T11:43:38.790420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Import data\n",
    "\n",
    "data_train = pd.read_csv(\"datasets/data_train.csv\")\n",
    "test_competition = pd.read_csv(\"datasets/test_competition.csv\")"
   ],
   "id": "aa6be0c72b85cd6b",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T11:43:38.925978Z",
     "start_time": "2024-11-07T11:43:38.896879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Split data\n",
    "\n",
    "# Drop ID column as it doesn't contribute to predictions\n",
    "if 'ID' in data_train.columns:\n",
    "    data_train = data_train.drop(columns=['ID'])\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data_train.drop(columns=['default.payment.next.month'])\n",
    "y = data_train['default.payment.next.month']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "417ffe7aaab180fb",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T11:43:38.988100Z",
     "start_time": "2024-11-07T11:43:38.975063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Initialize the Gradient Boosting Classifier\n",
    "model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Step 2: Hyperparameter tuning using RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': range(1, 30),\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}"
   ],
   "id": "474a6eb9bcd93100",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-07T11:43:39.037777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist, \n",
    "                                   n_iter=10, scoring='roc_auc', cv=5, random_state=42)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Evaluate the best model on validation data\n",
    "best_model = random_search.best_estimator_\n",
    "y_val_pred_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Calculate accuracy and AUC score\n",
    "accuracy = accuracy_score(y_val, best_model.predict(X_val))\n",
    "auc_score = roc_auc_score(y_val, y_val_pred_proba)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(f\"Validation AUC: {auc_score}\")"
   ],
   "id": "bc64991712753ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T11:42:43.199098Z",
     "start_time": "2024-11-07T11:42:43.131800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the test dataset\n",
    "test_data = pd.read_csv(\"datasets/test_competition.csv\")\n",
    "\n",
    "# Drop the 'ID' column from the test data if it exists\n",
    "if 'ID' in test_data.columns:\n",
    "    test_data = test_data.drop(columns=['ID'])\n",
    "\n",
    "# Use the trained model to predict probabilities on the test data\n",
    "test_predictions = best_model.predict_proba(test_data)[:, 1]\n",
    "\n",
    "# Select top 1000 clients with highest probability of default\n",
    "top_1000_risk_indices = np.argsort(test_predictions)[-1000:]\n",
    "submission = test_data.iloc[top_1000_risk_indices].copy()  # Avoid SettingWithCopyWarning\n",
    "submission['default_risk_score'] = test_predictions[top_1000_risk_indices]\n",
    "\n",
    "# Save the top 1000 highest-risk clients to a CSV file\n",
    "submission[['default_risk_score']].to_csv('top_1000_risk_clients.csv', index=False)"
   ],
   "id": "da63bb82c3745144",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- ID\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m     test_data \u001B[38;5;241m=\u001B[39m test_data\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mID\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Use the trained model to predict probabilities on the test data\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m test_predictions \u001B[38;5;241m=\u001B[39m \u001B[43mbest_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_proba\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_data\u001B[49m\u001B[43m)\u001B[49m[:, \u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Select top 1000 clients with highest probability of default\u001B[39;00m\n\u001B[0;32m     12\u001B[0m top_1000_risk_indices \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margsort(test_predictions)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1000\u001B[39m:]\n",
      "File \u001B[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1667\u001B[0m, in \u001B[0;36mGradientBoostingClassifier.predict_proba\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m   1646\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict_proba\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m   1647\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Predict class probabilities for X.\u001B[39;00m\n\u001B[0;32m   1648\u001B[0m \n\u001B[0;32m   1649\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1665\u001B[0m \u001B[38;5;124;03m        If the ``loss`` does not support probabilities.\u001B[39;00m\n\u001B[0;32m   1666\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1667\u001B[0m     raw_predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecision_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1668\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_loss\u001B[38;5;241m.\u001B[39mpredict_proba(raw_predictions)\n",
      "File \u001B[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1565\u001B[0m, in \u001B[0;36mGradientBoostingClassifier.decision_function\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m   1546\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecision_function\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m   1547\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute the decision function of ``X``.\u001B[39;00m\n\u001B[0;32m   1548\u001B[0m \n\u001B[0;32m   1549\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1563\u001B[0m \u001B[38;5;124;03m        array of shape (n_samples,).\u001B[39;00m\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1565\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1566\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDTYPE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mC\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[0;32m   1567\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1568\u001B[0m     raw_predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raw_predict(X)\n\u001B[0;32m   1569\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m raw_predictions\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\sklearn\\base.py:608\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[0;32m    537\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_validate_data\u001B[39m(\n\u001B[0;32m    538\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    539\u001B[0m     X\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mno_validation\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    544\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params,\n\u001B[0;32m    545\u001B[0m ):\n\u001B[0;32m    546\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001B[39;00m\n\u001B[0;32m    547\u001B[0m \n\u001B[0;32m    548\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    606\u001B[0m \u001B[38;5;124;03m        validated.\u001B[39;00m\n\u001B[0;32m    607\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 608\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_feature_names\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    610\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_tags()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequires_y\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m    611\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    612\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m estimator \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    613\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequires y to be passed, but the target y is None.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    614\u001B[0m         )\n",
      "File \u001B[1;32mC:\\laragon\\bin\\python\\python-3.10\\lib\\site-packages\\sklearn\\base.py:535\u001B[0m, in \u001B[0;36mBaseEstimator._check_feature_names\u001B[1;34m(self, X, reset)\u001B[0m\n\u001B[0;32m    530\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m missing_names \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m unexpected_names:\n\u001B[0;32m    531\u001B[0m     message \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    532\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFeature names must be in the same order as they were in fit.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    533\u001B[0m     )\n\u001B[1;32m--> 535\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(message)\n",
      "\u001B[1;31mValueError\u001B[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- ID\n"
     ]
    }
   ],
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
